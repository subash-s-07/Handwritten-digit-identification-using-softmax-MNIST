{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "mnist = pd.read_csv('total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffle_index = np.random.permutation(70000)\n",
    "X=mnist.drop('label',axis=1)\n",
    "Y=mnist['label']\n",
    "x_train, x_test, y_train, y_test = X[:60000], X[60000:], Y[:60000].astype(int), Y[60000:].astype(int)\n",
    "digit = np.array(x_train.iloc[2500])\n",
    "image = digit.reshape(28, 28)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_feature_vector(X):\n",
    "    return np.hstack((np.ones([len(X), 1]), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_compute_probabilities(X, theta):\n",
    "    #Arguments:\n",
    "    #X is a (nxd) matrix (numpy array)\n",
    "    #theta is a kxd matrix\n",
    "    \n",
    "    #Returns:\n",
    "    #H is a (kxn) matrix (numpy array) such that each column of H represents the probabilities that the ith\n",
    "    #data point takes on each label.\n",
    "    \n",
    "    #constructs the skeleton of the output matrix.\n",
    "    k = theta.shape[0]\n",
    "    n = X.shape[0]\n",
    "    H = np.zeros([k,n])\n",
    "\n",
    "     #loops over all the data points\n",
    "    for i in range(n):\n",
    "        dpoint = X[i]\n",
    "        #constructing a vector that we can take a maximum of to obtain constant c\n",
    "        c_vector = np.zeros(k)\n",
    "        for j in range(k):\n",
    "            c_vector[j] = (np.dot(theta[j], dpoint))\n",
    "            c = np.amax(c_vector)\n",
    "        summation = 0\n",
    "        \n",
    "        #for each data point we loop through all of the labels\n",
    "        for j in range(k): \n",
    "            exponent = np.dot(theta[j], dpoint) - c\n",
    "            summation += np.exp(exponent)\n",
    "            H[j][i] = np.exp(exponent)\n",
    "\n",
    "        H[:,i] = H[:,i]/summation\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.169336318969727"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    " #theta initialized to zero\n",
    "theta = np.zeros([10, x_train.shape[1]])\n",
    "\n",
    "start = time.time()\n",
    "probs = naive_compute_probabilities(x_train.to_numpy(), theta)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.36603093147278"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#theta randomly initialized\n",
    "theta = np.random.randint(0, 10, [10,x_train.shape[1]])\n",
    "\n",
    "start = time.time()\n",
    "probs = naive_compute_probabilities(x_train.to_numpy(), theta)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([8,8,8,8,8])\n",
    "\n",
    "a_dot_b = sum([a[i]*b[i] for i in range(len(a))])\n",
    "a_dot_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_compute_probabilities(X, theta):\n",
    "    #Arguments:\n",
    "    #X is a (nxd) matrix (numpy array)\n",
    "    #theta is a kxd matrix\n",
    "    \n",
    "    #Returns:\n",
    "    #H - a (kxn) matrix (numpy array) such that each column of H represents the probabilities that the ith\n",
    "    #data point takes on each label.\n",
    "    \n",
    "    theta_XT = np.matmul(theta, np.transpose(X))\n",
    "    #taking a columnwise max:\n",
    "    c = np.amax(theta_XT, axis = 0)\n",
    "    #elementwise exponentiation of theta_XT:\n",
    "    exp_matrix = np.exp(theta_XT - c)\n",
    "    #computing the normalization factors for each column of H:\n",
    "    sum_vector = np.sum(exp_matrix, axis = 0)\n",
    "    \n",
    "    #broadcasting!\n",
    "    return exp_matrix/sum_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4125423431396484"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.zeros([10, x_train.shape[1]])\n",
    "\n",
    "start = time.time()\n",
    "probs = vectorized_compute_probabilities(x_train.to_numpy(), theta)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9314146041870117"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.random.randint(0, 10, [10, x_train.shape[1]])\n",
    "\n",
    "start = time.time()\n",
    "probs = vectorized_compute_probabilities(x_train.to_numpy(), theta)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "def gradient_descent_iteration(X, Y, theta, alpha, lambda_factor):\n",
    "    \n",
    "    n = len(Y)\n",
    "    k = theta.shape[0]\n",
    "    data = [1]*n\n",
    "    \n",
    "    H = vectorized_compute_probabilities(X, theta)\n",
    "    #more efficient way to implement large sparse arrays:\n",
    "    M = sparse.coo_matrix((data, (Y, range(n))), shape=(k,n)).toarray()\n",
    "    \n",
    "    first_term = np.matmul(M-H, X)*(-1/n)\n",
    "    second_term = lambda_factor * theta\n",
    "\n",
    "    return theta - alpha * (first_term + second_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "\n",
    "    X = augment_feature_vector(X)\n",
    "    probabilities = vectorized_compute_probabilities(X, theta)\n",
    "    return np.argmax(probabilities, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(X, Y, theta):\n",
    "    predictions = predict(X, theta)\n",
    "    return np.mean(predictions == Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression(X, Y, alpha, lambda_factor, k, num_iterations):   \n",
    "    \n",
    "    X = augment_feature_vector(X)\n",
    "    theta = np.zeros([k, X.shape[1]])\n",
    "    for i in range(num_iterations):\n",
    "        theta = gradient_descent_iteration(X, Y, theta, alpha, lambda_factor)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using parameters suggested in prompt for original project but extending number of iterations of gradient\n",
    "#descent to 1000 instead of 150\n",
    "\n",
    "theta_final = softmax_regression(x_train, y_train, alpha = .3, \n",
    "                           lambda_factor = 1.0e-4, k = 10, num_iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "\n",
    "compute_accuracy(x_test, y_test, theta_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
